{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 76728,
          "databundleVersionId": 9057646,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Regression-Autogluon | 72973.86993",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'playground-series-s4e9:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F76728%2F9057646%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240904%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240904T025957Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D717de538a8442e27de26541732ba8d806340e5da2059e085bc229575cc27877543fcbf979a86bb021294e0ba204b4ee9911b9528c03fabda2578c3805548b6d4d1b4c65cdee9345b7906e89134c87deae6744c2a4c46dd570deaa7d1cc90accbb7afefdc9b6f893e352498b7becba9f64753116654e1bcf063a7dcdf3649067c3216b9befa3c4fb1c270cfc59e60f0b0bf8a0c4830d084542769907e3e4af4a0f8bcac1c8eb3dcab511baf534004933a415181a21f066a8abee5508e82cfa921d94798dba366e8457384a8deedeb7b67c230e582bffc0369521159ada41e8132f4ffa29a04ed1f7290ec3d0a1c054f1554fa42fa86058c9b668f18c4facf6849'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "VvaC-qTy-YZY"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-09-03T12:40:44.08731Z",
          "iopub.execute_input": "2024-09-03T12:40:44.087828Z",
          "iopub.status.idle": "2024-09-03T12:40:45.402805Z",
          "shell.execute_reply.started": "2024-09-03T12:40:44.087768Z",
          "shell.execute_reply": "2024-09-03T12:40:45.401646Z"
        },
        "trusted": true,
        "id": "QqAc6zOx-YZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/kaggle/input/playground-series-s4e9/train.csv')\n",
        "train_df.head(100)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T12:40:45.404713Z",
          "iopub.execute_input": "2024-09-03T12:40:45.405474Z",
          "iopub.status.idle": "2024-09-03T12:40:46.130428Z",
          "shell.execute_reply.started": "2024-09-03T12:40:45.405414Z",
          "shell.execute_reply": "2024-09-03T12:40:46.129232Z"
        },
        "trusted": true,
        "id": "tiY1lUUy-YZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/kaggle/input/playground-series-s4e9/test.csv')\n",
        "test_ids = test_df['id']\n",
        "test_df.head(100)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T14:12:22.977486Z",
          "iopub.execute_input": "2024-09-03T14:12:22.978684Z",
          "iopub.status.idle": "2024-09-03T14:12:23.583731Z",
          "shell.execute_reply.started": "2024-09-03T14:12:22.978629Z",
          "shell.execute_reply": "2024-09-03T14:12:23.582412Z"
        },
        "trusted": true,
        "id": "azNgp7SL-YZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_rows_train = train_df.isnull().sum()\n",
        "print(missing_rows_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T12:40:46.557758Z",
          "iopub.execute_input": "2024-09-03T12:40:46.558212Z",
          "iopub.status.idle": "2024-09-03T12:40:46.746964Z",
          "shell.execute_reply.started": "2024-09-03T12:40:46.558156Z",
          "shell.execute_reply": "2024-09-03T12:40:46.745377Z"
        },
        "trusted": true,
        "id": "VU8Zd1oA-YZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_rows_test = test_df.isnull().sum()\n",
        "print(missing_rows_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T12:40:46.748838Z",
          "iopub.execute_input": "2024-09-03T12:40:46.749427Z",
          "iopub.status.idle": "2024-09-03T12:40:46.877646Z",
          "shell.execute_reply.started": "2024-09-03T12:40:46.74937Z",
          "shell.execute_reply": "2024-09-03T12:40:46.876318Z"
        },
        "trusted": true,
        "id": "rcE4SDtR-YZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T12:40:46.878972Z",
          "iopub.execute_input": "2024-09-03T12:40:46.879773Z",
          "iopub.status.idle": "2024-09-03T12:40:46.884938Z",
          "shell.execute_reply.started": "2024-09-03T12:40:46.879715Z",
          "shell.execute_reply": "2024-09-03T12:40:46.883725Z"
        },
        "trusted": true,
        "id": "Ps0UY1Dm-YZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Function to train a Random Forest model and predict missing values\n",
        "def train_and_predict(df, target_column):\n",
        "    # Separate the data into features and target\n",
        "    non_missing = df[df[target_column].notnull()]\n",
        "    missing = df[df[target_column].isnull()]\n",
        "\n",
        "    # Features and target for training\n",
        "    X = non_missing.drop(columns=[target_column])\n",
        "    y = non_missing[target_column]\n",
        "\n",
        "    # Categorical features to encode\n",
        "    categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    # Create a column transformer for one-hot encoding\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "    # Create a pipeline that first transforms the data then fits the model\n",
        "    model = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', RandomForestClassifier(random_state=42))\n",
        "    ])\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the Random Forest model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict missing values\n",
        "    if not missing.empty:\n",
        "        missing_predictions = model.predict(missing.drop(columns=[target_column]))\n",
        "        df.loc[missing.index, target_column] = missing_predictions\n",
        "\n",
        "# Handle missing values for 'fuel_type'\n",
        "train_and_predict(train_df, 'fuel_type')\n",
        "\n",
        "# Handle missing values for 'accident'\n",
        "train_and_predict(train_df, 'accident')\n",
        "\n",
        "# Handle missing values for 'clean_title'\n",
        "train_and_predict(train_df, 'clean_title')\n",
        "\n",
        "# Final check\n",
        "print(train_df.isnull().sum())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T12:40:46.886539Z",
          "iopub.execute_input": "2024-09-03T12:40:46.886981Z",
          "iopub.status.idle": "2024-09-03T12:53:53.059697Z",
          "shell.execute_reply.started": "2024-09-03T12:40:46.886941Z",
          "shell.execute_reply": "2024-09-03T12:53:53.058459Z"
        },
        "trusted": true,
        "id": "p228Jqfd-YZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values for 'fuel_type'\n",
        "train_and_predict(test_df, 'fuel_type')\n",
        "\n",
        "# Handle missing values for 'accident'\n",
        "train_and_predict(test_df, 'accident')\n",
        "\n",
        "# Handle missing values for 'clean_title'\n",
        "train_and_predict(test_df, 'clean_title')\n",
        "\n",
        "# Final check\n",
        "print(test_df.isnull().sum())\n",
        "\n",
        "test_df=test_df.drop('clean_title', axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T13:54:46.398314Z",
          "iopub.execute_input": "2024-09-03T13:54:46.39974Z",
          "iopub.status.idle": "2024-09-03T14:01:48.06636Z",
          "shell.execute_reply.started": "2024-09-03T13:54:46.399677Z",
          "shell.execute_reply": "2024-09-03T14:01:48.064989Z"
        },
        "trusted": true,
        "id": "W0_FNupj-YZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=train_df.drop('clean_title', axis=1)\n",
        "train_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T13:14:23.929405Z",
          "iopub.execute_input": "2024-09-03T13:14:23.929909Z",
          "iopub.status.idle": "2024-09-03T13:14:23.962529Z",
          "shell.execute_reply.started": "2024-09-03T13:14:23.92986Z",
          "shell.execute_reply": "2024-09-03T13:14:23.961181Z"
        },
        "trusted": true,
        "id": "E1AGv2gu-YZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray==2.10.0\n",
        "!pip install autogluon.tabular\n",
        "!pip install -U ipywidgets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T12:53:53.08245Z",
          "iopub.execute_input": "2024-09-03T12:53:53.082861Z",
          "iopub.status.idle": "2024-09-03T12:54:45.583885Z",
          "shell.execute_reply.started": "2024-09-03T12:53:53.082818Z",
          "shell.execute_reply": "2024-09-03T12:54:45.582262Z"
        },
        "trusted": true,
        "id": "IOIealUP-YZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T12:54:45.585834Z",
          "iopub.execute_input": "2024-09-03T12:54:45.58647Z",
          "iopub.status.idle": "2024-09-03T12:54:46.092574Z",
          "shell.execute_reply.started": "2024-09-03T12:54:45.586414Z",
          "shell.execute_reply": "2024-09-03T12:54:46.091091Z"
        },
        "trusted": true,
        "id": "64XCOVRe-YZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.describe())\n",
        "print(train_df.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T13:14:31.642556Z",
          "iopub.execute_input": "2024-09-03T13:14:31.643285Z",
          "iopub.status.idle": "2024-09-03T13:14:31.853557Z",
          "shell.execute_reply.started": "2024-09-03T13:14:31.643159Z",
          "shell.execute_reply": "2024-09-03T13:14:31.85215Z"
        },
        "trusted": true,
        "id": "h_oNvptW-YZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in train_df.columns:\n",
        "    print(f\"{column}: {train_df[column].nunique()} unique values\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T13:14:42.972977Z",
          "iopub.execute_input": "2024-09-03T13:14:42.97351Z",
          "iopub.status.idle": "2024-09-03T13:14:43.14748Z",
          "shell.execute_reply.started": "2024-09-03T13:14:42.973438Z",
          "shell.execute_reply": "2024-09-03T13:14:43.146262Z"
        },
        "trusted": true,
        "id": "8UBI3tCo-YZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = 'price'\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric='rmse', problem_type=\"regression\").fit(\n",
        "    train_df,\n",
        "    presets='medium_quality_faster_train',\n",
        "    time_limit=3600,  # Try a shorter time limit for quick testing\n",
        "    verbosity=2\n",
        ")\n",
        "\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T13:19:35.597802Z",
          "iopub.execute_input": "2024-09-03T13:19:35.598297Z",
          "iopub.status.idle": "2024-09-03T13:48:18.789642Z",
          "shell.execute_reply.started": "2024-09-03T13:19:35.598244Z",
          "shell.execute_reply": "2024-09-03T13:48:18.787757Z"
        },
        "trusted": true,
        "id": "Dvz7YaJB-YZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.leaderboard()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T13:52:37.841119Z",
          "iopub.execute_input": "2024-09-03T13:52:37.842664Z",
          "iopub.status.idle": "2024-09-03T13:52:37.873075Z",
          "shell.execute_reply.started": "2024-09-03T13:52:37.842609Z",
          "shell.execute_reply": "2024-09-03T13:52:37.871586Z"
        },
        "trusted": true,
        "id": "nWQXy31Y-YZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predictor.predict(test_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T14:04:45.407789Z",
          "iopub.execute_input": "2024-09-03T14:04:45.408375Z",
          "iopub.status.idle": "2024-09-03T14:05:03.129309Z",
          "shell.execute_reply.started": "2024-09-03T14:04:45.408323Z",
          "shell.execute_reply": "2024-09-03T14:05:03.127985Z"
        },
        "trusted": true,
        "id": "JCo4YNgp-YZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'price': y_pred\n",
        "})\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the predictions\n",
        "print(submission.head(10))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T14:12:32.316258Z",
          "iopub.execute_input": "2024-09-03T14:12:32.317321Z",
          "iopub.status.idle": "2024-09-03T14:12:32.642708Z",
          "shell.execute_reply.started": "2024-09-03T14:12:32.317268Z",
          "shell.execute_reply": "2024-09-03T14:12:32.641584Z"
        },
        "trusted": true,
        "id": "Z9OTevM3-YZn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}